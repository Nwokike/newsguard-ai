{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX49cUo-3-M0",
        "outputId": "96e1c752-62a1-485b-d7ba-7bd832361830"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ DataFrames loaded successfully.\n",
            "Fake News Count: 23481\n",
            "True News Count: 21417\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- Load the datasets ---\n",
        "# Assuming files are uploaded to your Colab session storage\n",
        "try:\n",
        "    df_fake = pd.read_csv('Fake.csv')\n",
        "    df_true = pd.read_csv('True.csv')\n",
        "    print(\"✅ DataFrames loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"❌ Error: Ensure 'Fake.csv' and 'True.csv' are uploaded to your Colab environment.\")\n",
        "\n",
        "# Display initial information\n",
        "print(f\"Fake News Count: {len(df_fake)}\")\n",
        "print(f\"True News Count: {len(df_true)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgQwf3cH7uNk",
        "outputId": "6f3dc339-05d4-4493-e383-77d263a37dc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ DataFrames combined and labeled.\n",
            "Combined DataFrame Sample:\n",
            "                                               title  \\\n",
            "0  Malaysia ready to provide temporary shelter fo...   \n",
            "1  Exclusive: Cameroonian troops entered Nigeria ...   \n",
            "2  INTEL CHAIR Stands Up To Dems Calling For His ...   \n",
            "\n",
            "                                                text          subject  \\\n",
            "0  KUALA LUMPUR (Reuters) - Malaysia s coast guar...        worldnews   \n",
            "1  ABUJA/DAKAR (Reuters) - Cameroonian troops thi...        worldnews   \n",
            "2  .@Rep_DevinNunes:  I m sure that @TheDemocrats...  Government News   \n",
            "\n",
            "                 date  label  \n",
            "0  September 8, 2017       1  \n",
            "1  December 20, 2017       1  \n",
            "2        Mar 27, 2017      0  \n"
          ]
        }
      ],
      "source": [
        "# Add label column\n",
        "df_fake['label'] = 0\n",
        "df_true['label'] = 1\n",
        "\n",
        "# Combine datasets and shuffle the order for good measure\n",
        "df_combined = pd.concat([df_fake, df_true], ignore_index=True, sort=False)\n",
        "df_combined = df_combined.sample(frac=1).reset_index(drop=True) # Shuffle data\n",
        "\n",
        "print(\"✅ DataFrames combined and labeled.\")\n",
        "print(\"Combined DataFrame Sample:\")\n",
        "print(df_combined.head(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEaTDCNG8WaT",
        "outputId": "26ed4337-1c13-4825-bd60-5fdedd9d3ac5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Text feature created and cleaned.\n",
            "\n",
            "Comparison (Original vs. Cleaned):\n",
            "full_text       Malaysia ready to provide temporary shelter fo...\n",
            "cleaned_text    malaysia ready to provide temporary shelter fo...\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Drop unused columns and create 'full_text' feature\n",
        "df_combined = df_combined.drop(['subject', 'date'], axis=1)\n",
        "\n",
        "# Combine 'title' and 'text' to form the feature the model will analyze\n",
        "df_combined['full_text'] = df_combined['title'] + ' ' + df_combined['text']\n",
        "\n",
        "# Step 3: Define and apply the text cleaning function\n",
        "def clean_text(text):\n",
        "    # 1. Lowercase\n",
        "    text = text.lower()\n",
        "    # 2. Remove URLs\n",
        "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
        "    # 3. Remove punctuation and numbers (keeping only letters and spaces)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    return text\n",
        "\n",
        "df_combined['cleaned_text'] = df_combined['full_text'].apply(clean_text)\n",
        "\n",
        "print(\"✅ Text feature created and cleaned.\")\n",
        "print(\"\\nComparison (Original vs. Cleaned):\")\n",
        "print(df_combined[['full_text', 'cleaned_text']].iloc[0].T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u3vv2e98tyD",
        "outputId": "461ebe79-4b3f-43ed-aa69-9f19af6b5ace"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Final Data Split Status:\n",
            "Total Samples: 44898\n",
            "Training Samples: 35918 (80%)\n",
            "Testing Samples: 8980 (20%)\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Separate Features (X) and Target (y)\n",
        "X = df_combined['cleaned_text'] # Input features (cleaned text)\n",
        "y = df_combined['label']      # Target variable (0 or 1)\n",
        "\n",
        "# Step 5: Split the data (80% Training, 20% Testing)\n",
        "# stratify=y ensures the 0/1 ratio is maintained in both train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"\\n✅ Final Data Split Status:\")\n",
        "print(f\"Total Samples: {len(df_combined)}\")\n",
        "print(f\"Training Samples: {len(X_train)} (80%)\")\n",
        "print(f\"Testing Samples: {len(X_test)} (20%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASVfGyZR-h8m",
        "outputId": "96c3aa5c-5975-42ba-8afc-c73bf98fc1c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ TF-IDF Vectorization complete.\n",
            "Shape of Training Matrix (Samples, Features): (35918, 10000)\n",
            "Shape of Testing Matrix (Samples, Features): (8980, 10000)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize the TF-IDF Vectorizer\n",
        "# max_features=10000 ensures we only use the 10,000 most common words, reducing complexity\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)\n",
        "\n",
        "# Fit the vectorizer ONLY on the training data (X_train)\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using the fitted vectorizer\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "print(\"✅ TF-IDF Vectorization complete.\")\n",
        "print(f\"Shape of Training Matrix (Samples, Features): {X_train_vectorized.shape}\")\n",
        "print(f\"Shape of Testing Matrix (Samples, Features): {X_test_vectorized.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47gALaf8_b7G",
        "outputId": "6851d985-1b29-471f-8431-0c63e848ae6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⏳ Training Logistic Regression Model...\n",
            "✅ Model training complete.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Initialize and train the model\n",
        "model = LogisticRegression(random_state=42)\n",
        "\n",
        "print(\"⏳ Training Logistic Regression Model...\")\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "print(\"✅ Model training complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYK75gFT_iSE",
        "outputId": "d77f8c27-7f82-4f87-bf38-daa48992ed2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Model Evaluation Results ---\n",
            "Accuracy: 0.9899 (Overall Correctness)\n",
            "Precision: 0.9884 (When model predicts REAL, how often is it right?)\n",
            "Recall: 0.9904 (Out of all REAL news, how many did the model find?)\n",
            "F1 Score: 0.9894 (Balance between Precision and Recall)\n",
            "\n",
            "Confusion Matrix (True vs Predicted):\n",
            "[[4646   50]\n",
            " [  41 4243]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test_vectorized)\n",
        "\n",
        "# Calculate key performance metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"\\n--- Model Evaluation Results ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f} (Overall Correctness)\")\n",
        "print(f\"Precision: {precision:.4f} (When model predicts REAL, how often is it right?)\")\n",
        "print(f\"Recall: {recall:.4f} (Out of all REAL news, how many did the model find?)\")\n",
        "print(f\"F1 Score: {f1:.4f} (Balance between Precision and Recall)\")\n",
        "print(\"\\nConfusion Matrix (True vs Predicted):\")\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWcjOqMK_mvD",
        "outputId": "3ae50fec-97d6-4d96-a499-237589a2ed30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Trained Model saved as: fake_news_model.pkl\n",
            "✅ Fitted Vectorizer saved as: fake_news_vectorizer.pkl\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "# Define the filenames for your saved assets\n",
        "# These files will go into your local newsguard-ai/models/ folder\n",
        "model_filename = 'fake_news_model.pkl'\n",
        "vectorizer_filename = 'fake_news_vectorizer.pkl'\n",
        "\n",
        "# --- Save the Trained Model ---\n",
        "with open(model_filename, 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "print(f\"✅ Trained Model saved as: {model_filename}\")\n",
        "\n",
        "# --- Save the Fitted Vectorizer (REQUIRED for new predictions) ---\n",
        "with open(vectorizer_filename, 'wb') as file:\n",
        "    pickle.dump(vectorizer, file)\n",
        "print(f\"✅ Fitted Vectorizer saved as: {vectorizer_filename}\")\n",
        "\n",
        "# IMPORTANT: You must manually download these two files\n",
        "# (fake_news_model.pkl and fake_news_vectorizer.pkl)\n",
        "# from the Colab file pane (left-hand sidebar) to your local machine!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eA3REXHLARwz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
